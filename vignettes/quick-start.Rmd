---
title: "Analyzing single-cell RNA-seq perturbation with DECAL"
author: "AndrÃ© M. Ribeiro-dos-Santos"
date: "`r format(Sys.Date(), '%m/%d/%Y')`"
abstract: >
  TODO: Package abstract
  decal package version: `r packageVersion("decal")`
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    df_print: kable
    fig_width: 6
    fig_caption: true
bibliography: decal.bib
vignette: >
  %\VignetteIndexEntry{Analyzing single-cell RNA-seq perturbation with scCloneDE}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  tidy = FALSE, cache = FALSE, dev = "png", collapse = TRUE, comment = "#>",
  message = FALSE, error = FALSE, warning = TRUE
)
options(scipen = 1, digits = 2)
```

# Default Workflow

**DECAL** (**D**ifferential **E**xpression analysis of **C**lonal
**A**lterations **L**ocal effects) provide you tools to conduct differential
expression analysis of single-cell perturbations to potential interacting
genes.
Similar to other expression analysis tools, it models gene expression using
a _Negative Binomial_ (or _Gamma-Poisson_) regression, modeling each gene
UMI count by the cell total count and the cell alteration status.

## Features

- `decal` is compatible with **tidyverse** analysis.
- Includes a suit of simulation functions to generate your own dataset based
  `decal` model and evaluate your statistical power.
- Package has few dependencies, requiring only `MASS`, `fastglm` and `Matrix`.
- Can evaluate specific clonal alteration and gene effect, instead of
  modeling all genes and all alterations. This allow us to quickly investigate
  a large number of interactions skipping unlikely effects.

## Installation

To install `decal` package current version, open your R terminal and type:

```{r installation, eval = FALSE}
## Install remotes if not available with
## install.install.packages("remotes")
remotes::install_github("mauranolab/decal")
```

## Quick Start

`decal` is the package main function which estimates each gene dispersion
($\theta$) parameter and fit a _Negative Binomial_ regression to each gene
and alteration pair specified to evaluate the perturbation statistical
significance.
It requires three parameters a UMI count matrix, a list specifying your clones
cell (count matrix columns) composition, and a table indicating the potential
alteration and affected gene to evaluate.

Below we show a quick example of `decal` analysis using a simulated dataset
included with our package.

```{r quick_start}
library(decal)

data("sim_decal")
perturbations <- sim_decal$perturbations
count <- sim_decal$count
clone <- sim_decal$clone

head(perturbations)
```

Our dataset (`sim_decal`) is composed by the three required parameters:

- a UMI count matrix (`count`);
- a list dividing our cells by clonal population (`clone`);
- and a table (`perturbations`) indicating potential interactions to evaluate,
  specified by the perturbed `clone` and candidate `gene`.

With these inputs, we can run the full analysis using the `decal` function as
follow:

```{r quick_start_run}
res <- decal(perturbations, count, clone)
head(res)
```

`decal` function conducts the whole differential analysis, by estimating each
gene dispersion and fitting a negative binomial regression to evaluate each
interaction statistical significance.
Finally, `decal` updates `perturbations` table to include the following
results:

- `n0` and `n1`: number of non-perturbed and perturbed cells, respectively.
- `x0` and `x1`: average UMI count among perturbed and non-perturbed cells,
  respectively.
- `mu`: average UMI count among all cells.
- `xb`: expected average UMI count of perturbed cells.
- `theta`: estimated _negative binomial_ dispersion parameter.
- `z`: estimated perturbation z-score.
- `lfc`: _log2 fold-change_ of perturbed cells gene expression.
- `pvalue` and `p_adjusted`: perturbation _t-test_ significance values.

## Exploring decal results

Let's explore `decal` results. Admitting a _false discovery rate_ (_FDR_) of
5%, we can determinate significantly differentiate interactions by picking
those with `p_adjusted < 0.05`.
Below we present the top 5 interactions with highest reducing and increasing
gene expression effect (as measured by `lfc`).

```{r quick_start_significant}
sig <- subset(res, p_adjusted < 0.05)
sig <- sig[order(sig$lfc), ]
## select first 5 and last 5 as `sig` is ordered by lfc
pick <- c(1:5, nrow(sig) - 1:5)
sig[pick,]
```

To visualize the perturbation effect, let's plot the top 3 interactions
increasing and reducing gene expression.

```{r quick_start_plot_it, fig.height = 4}
## log-transform
log10p <- function(x) log10(x + 1)
## normalizing size factor to average cell depth
sf <- mean(colSums(count)) / colSums(count)
## select first and last 3 rows
pick <- c(1:3, nrow(sig) - 1:3)

par(mfrow = c(2, 3))
for (i in pick) {
  ## Determinate perturbed and unperturbed cells
  x <- colnames(count) %in% clone[[sig$clone[i]]]
  ## Calculate normalized expression count
  y <- count[sig$gene[i],] * sf
  ## plot jitter
  title <- paste0(sig$clone[i], "+", sig$gene[i],"\nLFC: ", round(sig$lfc[i], 2))
  plot(
    x + runif(length(x), -.3, .3), log10p(y), main = title,
    axes = FALSE, xlab = "", ylab = "Normalize UMI count",
    xlim = c(-.5, 1.5), ylim = c(0.9, 1.1) * range(log10p(y))
  )
  axis(1, at = 0:1, labels = c("perturbed", "unperturbed"), las = 2)
  axis(2, at = log10p(c(0, 2, 5, 10, 20, 50, 100)), labels = c(0, 2, 5, 10, 20, 50, 100))
  ## add 95% error bar
  ymed <- c(sig$mu[i], sig$xb[i])
  ylow <- qnbinom(0.025, size = sig$theta[i], mu = ymed)
  yupr <- qnbinom(0.975, size = sig$theta[i], mu = ymed)
  points(c(0, 1), log10p(ymed), col = "firebrick", cex = 2, pch = 16)
  arrows(
    x0 = c(0, 1), y0 = log10p(ylow), x1 = c(0, 1), y1 = log10p(yupr),
    code = 3, angle = 90, col = "firebrick", length = .1, lwd = 2
  )
}
```

## Evaluating `decal` results

Since `sim_decal` is a simulated dataset with some real expression perturbation
introduced, we can measure how well `decal` identifies real change.
The real expression perturbation introduced in our simulated dataset is
indicated by `expected_lfc` column in `perturbations` table, where a
`expected_lfc == 0` indicate no gene was applied.
Admitting a _FDR_ of 5%, we can measure our results with the confusion matrix
below.

```{r quick_start_confusion}
conf_mat <- table(
  real = res$expected_lfc != 0,
  estimated = res$p_adjusted < 0.05
)
round(prop.table(conf_mat, 1), 3)
```

Based on this confusion matrix, our model presented:

- **Accuracy**: `r round(sum(diag(conf_mat)) / sum(conf_mat), 3)`
- **Precision**: `r round(conf_mat[2, 2] / sum(conf_mat[2,]), 3)`
- **Recall**: `r round(conf_mat[2, 2] / sum(conf_mat[,2]), 3)`
- **Observed FDR**: `r round((conf_mat[1, 2] + conf_mat[2, 1]) / sum(conf_mat), 3)`

All of these are good metrics and within the expected results. Next, we can
evaluated how well our model estimated the real _log-2 fold-change_ applied.
Illustrated below is the `lfc` distribution as estimated by `decal` for each
real perturbation value applied (`expected_lfc`).

```{r quick_start_hist}
lfc_histogram <- function(lfc, fn = function(x) { x$count / sum(x$count) }) {
  hist_breaks <- c(-Inf, seq(-4, 4, length.out = 50), Inf)
  hist_counts <- lapply(lfc, hist, breaks = hist_breaks, plot = FALSE)
  hist_ymax <- max(sapply(hist_counts, fn))
  plot(c(-4, 4), c(0, hist_ymax), type = "n",
    xlab = "Estimated LFC", ylab = "Proportion of interactions")
  for(i in seq_along(hist_counts)) {
    lines(hist_counts[[i]]$mids, fn(hist_counts[[i]]), col = i, type = "s")
  }
  legend("topleft", title = "Real LFC", legend = names(hist_counts),
    col = seq_along(hist_counts), bty = "n", lty = 1, lwd = 2, ncol = 2)
}

lfc_histogram(split(res$lfc, res$expected_lfc))
```

We can also measure the estimate _Mean Squared Error_ (_MSE_) and _Rooted MSE_
(_RMSE_).

```{r quick_start_rmse}
err <- (res$lfc - res$expected_lfc)**2
err <- split(err, res$expected_lfc)
mse <- sapply(err, mean, na.rm = TRUE)

data.frame(
  N = sapply(err, length),
  MSE = mse,
  RMSE = sqrt(mse)
)
```

Although _MSE_ and _RMSE_ increase for negative _LFC_, the model still presents
a high accuracy and precision when estimating real perturbations effects.

# Understanding arguments

To run `decal` function, it requires three main parameters:

1. `perturbations`, a table of potential interactions to be evaluated,
identified by a `clone` and `gene` pair.
2. `count`, a UMI count matrix.
3. `clone`, a list of cells defining each clone compositions.

## Electing potential gene perturbation

Since `decal` was designed to explore specific gene perturbations, it requires
you to specify clone and gene pairs to evaluate expression change among the
cells within the clone.
In our original study, we located our perturbations and evaluated their impact
to all genes TSS within _250Kbp_ of the perturbation.


Since we aim to explore specific gene perturbations, we must specify pairs of
clone population and genes (or features) to evaluate expression change among
the clone cells in regards to all others.
In our original study, we located our perturbations and evaluated expression
change to all genes with TSS within _250Kbp_ of the perturbation.
Here, we specify the these pairs of clone and perturbed genes to evaluate as
a table with a `clone` and `gene` column indicating the clone/gene id
(as character) or index (as integer), such as the example below:

```{r var_interactions}
head(perturbations)
```

## Defining your experiment clonal structure

`decal` allow you to explore multiple cell groups and explore specific gene
expression change caused to this group of cells. In our experiment, we used
an adjacent dataset to define your experiment clonal populations. This clonal
structure is specified in `clone` as a list of vectors specifying the set of
cells that define each clone. Either as a character vector of cells id
(specify to `count` column names) or a integer vector (specifying `count`
column indexes), such as the example below:

```{r var_clone}
clone[1:2]
```

## Reducing noise and increasing power

To improve your findings, `decal` includes some filtering arguments to avoid
testing interactions with low statistical power. Filters include:

- `min_x`: minimal average UMI count on perturbed and unperturbed cells
  (indicated by `x1` and `x0` on resulting table, respectively).
- `min_n`: minimal number of perturbed cells (indicated by `n1`).
- `min_mu`: minimal global average count (indicated by `mu`), also skips
  `theta` estimation.

Interactions that doesn't met all of these requirements are skipped and no
differential expression analysis is conducted, eventhough they are no removed
from the results.
By default, `min_x = 1`; `min_n = 2`; and `min_mu = 0.05`.

# Understanding `decal` model

## Statistical model

The `decal` statistical model is based on the observations from
@svensson_droplet_2020 and @townes_feature_2019 that UMI counts of a particular
gene approximates a _Poisson_ or _Negative Binomial_ distribution in a
single-cell RNA-seq experiment.
Thus, we proposed to model the observed counts as follow:

$$Y_{gc} \sim NB(\mu_{gci}, \theta_g)$$

where $Y_{cg}$ is the UMI count for gene _g_ and cell _c_ modeled using a
_negative binomial_ distribution with expected count $\mu_{cgi}$ and a
gene-specific dispersion parameter $\theta_g$.

$$log(\mu_{gci}) = log(D_c) + \beta_g + \beta_x X_{ci}$$

The log expected count ($log(\mu_{cgi})$) is proportional to the perturbation
effect ($\beta_x$) of a specific clone _i_ indicated by $X_{ci}$ (where
$X_{ci} == 1$ if cell belongs to the perturbed clone or $X_{ci} == 0$
otherwise) and offseted by the log cell total UMI count
($D_c = \sum_g Y_{cg}$).

The parameter $\theta_g$ defines the model dispersion where smaller values
produce a wider distribution and higher values produce a tighter distribution
that coincides with a _Poisson_ distribution. Such as the model variance is
defined as follow:

$$Var(Y_{cg}) = E[(Y_{cg} - \mu_{cgi})^2] = \mu_{cgi} + \mu_{cgi}^2/\theta_g$$
$$\lim_{\theta\to\infty} NB(\mu, \theta) = Pois(\mu)$$

This modeling approach is similar to previously published models such as edgeR
[@robinson_edger_2010; @mccarthy_differential_2012 ], DESeq2
[@anders_differential_2010; @love_moderated_2014], and glmGamPoi
[@ahlmann-eltze_glmgampoi_2021].
But it differs in two points: (i) to estimate $\theta_g$ we adopted a
regularized estimation strategy to make it robust to sampling noise in low
expression genes; and (ii) instead of fitting the model to all genes, it fits
and measure specific perturbation to gene.

## Estimating dispersion

Here we apply the strategy described by @hafemeister_normalization_2019 to
estimate $\theta_g$.
This strategy consists in first selecting at least 2000 genes and estimate of
the expected count ($mu_{cg}$) using a Poisson regression offseted by the log
cell total count (modeled as $Y_{cg} \sim Poi(mu_{cg})$, such as
$log(mu_{cg}) = \beta_g + D_c$).
Using $mu_{cg}$ and a maximum likelihood estimator to make a naive estimate of
$\theta_g$.
Next, we regularize our naive estimate by fitting a kernel smooth regression as
function of the gene average count ($\sum_g Y_{cg} / N$) to produce
our final $\theta_g$ estimate for all other genes.

```{r}
raw_theta <- attr(res, "raw_theta")
mu <- rowMeans(count)
mu_breaks <- c(0.01, 0.1, 1, 2, 5, 10, 20, 50, 100)

plot(log10(mu), raw_theta,
  xlab = "Average expression (mu)",
  ylab = expression(theta), ylim = c(0, 150))
abline(h = 100)
lines(log10(res$mu[order(res$mu)]), res$theta[order(res$mu)], col = 2, lwd = 3)
axis(1, at = log10(mu_breaks), labels = mu_breaks)
legend(
  "topleft", c("Naive Estimate", "Regularized Estimate", "Real"),
  pch = c(1, NA, NA), lty = c(NA, 1, 1), col = c(1, 2, 1)
)
```

## Assumptions and Caveats

This statistical model implies some assumptions and caveats:

1. The UMI count distribution is independent between genes, which is usually
  true for single-cell experiments due to large quantity of genes and small
  proportion of counts each of them represent.
2. The effect of individual clones are not enough to disrupt the unperturbed
  cells expression estimates. For such assumption, the number of perturbated
  cells of any clone must be much smaller than the total number of cells
  available (`n1 << n0`). This allow us to explore each clone independently
  since it makes unlikely a gene unperturbed estimate is affected by other
  clones, since they don't represent enough cells to disrupt the overall gene
  expression.
3. The cells represent a uniform population differing only by the induced
  perturbations. This can easily be obtained when the experiment is conducted
  in a cell culture.

# Simulating

Since many factor can affect your experiment, we included to `decal` a way to
simulate a dataset under our model assumptions.
These tools will allow you to evaluate your tests **power** and **sensitivity**
under the different conditions you may find yourself.

`decal` simulation suite is compose of various functions to generate a count
matrix (`sim_count` and `sim_count_from_data`), randomly assign cells to
different clones (`sim_clone` and `sim_clone_range`), and generate a full
experiment dataset (`sim_experiment` and `sim_experiment_from_data`).
Here we will use `sim_experiment` and `sim_experiment_from_data` to generate
our examples, but the other functions behave similarly.

## Evaluating our model under null hypothesis

Under the null hypothesis, we expect that our perturbations produce no
expression change to nearby genes.
Admitting a significance level of 5% and that `decal` statistical model holds,
we would expect that the resulting z-score present a normal distribution
centered at 0, p-value have a uniform distribution and about 5% of the tests
below our significance threshold.

Given an existing dataset, we can evaluate if our model holds by randomly
recombining clone and gene pairs.

```{r sim_randomization, fig.height=2.5, fig.width=8}
rnd <- unique(data.frame(
  clone = sample(perturbations$clone),
  gene = sample(perturbations$gene)
))
## remove previous clone + gene pairs
rnd <- rnd[!paste(rnd$gene, rnd$clone) %in% paste(perturbations$gene, perturbations$clone),]
rnd_res <- decal(rnd, count, clone)
rnd_res <- subset(rnd_res, !is.na(rnd_res$pvalue))

par(mfrow = c(1, 3))
hist(rnd_res$z, xlab = "Z-score", main = "")
hist(rnd_res$pvalue, xlab = "Observed Pvalue", main = "")
hist(rnd_res$p_adjusted, xlab = "Observed Qvalue", main = "")

mean(rnd_res$pvalue < 0.05)
mean(rnd_res$p_adjusted < 0.05)
```

As expected, this experiment z-score presented the expected _z-score_ and
_p-value_ distribution and the ratio of tests with p-value below the
significance threshold (`r mean(rnd_res$pvalue < 0.05)`) within the expected
5% at random.

We can conduct a similar experiment producing a random count matrix based
on your experiment counts. `sim_count_from_data` will simulate a UMI count
matrix with the same dimensions as your experiment with cells total UMI count
and gene average expression similar to your reference count matrix.

```{r, fig.height=2.5, fig.width=8}
rnd_count <- sim_count_from_data(count)

rnd_res <- decal(perturbations, rnd_count, clone)
rnd_res <- subset(rnd_res, !is.na(rnd_res$pvalue))

par(mfrow = c(1, 3))
hist(rnd_res$z, xlab = "Z-score", main = "")
hist(rnd_res$pvalue, xlab = "Observed Pvalue", main = "")
hist(rnd_res$p_adjusted, xlab = "Observed Qvalue", main = "")
```

## Estimating your experiment power

Another usufull application of `decal` simulation suite is conducting a power
analysis to decide how much should you sequence or to define your tests filters.
In the example below, we generated an experiment using
`sim_experiment_from_data` which generates a random count matrix, a clone
assignment list, and a perturbation table.
The generated count matrix is based on your experiment matrix with the same
dimensions, similar cells total count and gene average expression.
The clone list is composed of 100 clones with 5 to 20 cells each.
Perturbation table indicates pairs of clone and genes and the log2 fold-change
applied, where for each clone a gene was randomly to apply a effect indicated
by `lfc`. In this case, for each clone, 180 genes were selected and listed in
`pwr_dat$perturbations` and among them 20 were perturbed by a log2 fold-change
of -2, -1, 1, and 2.

```{r power, fig.height=3, fig.width=8}
pwr_lfc <- c(rep(c(-2, -1, 1, 2), each = 20), rep(0, 100))
pwr_dat <- sim_experiment_from_data(
  count, lfc = pwr_lfc, nclones = 100, min_n = 5, max_n = 20
)
pwr_res <- decal(pwr_dat$perturbations, pwr_dat$count, pwr_dat$clone)
pwr_res <- subset(pwr_res, !is.na(pvalue))
```

Adminitting a 5% FDR, we can estimated the ratio of the truly perturbated
gene and clone pairs were detected by `decal` (left plot) and the clone
size frequency (right plot).
For all log2 fold-change applied here, `decal` obtained a power close to 80%
that indicate que performance of the model.

```{r}
par(mfrow = c(1, 2))
barplot(
  sapply(split(
    pwr_res$p_adjusted[pwr_res$expected_lfc != 0] < 0.05,
    pwr_res$expected_lfc[pwr_res$expected_lfc != 0]
  ), mean),
  xlab = "LFC", ylab = "Power")
abline(h = 0.8, lty = 2, col = "firebrick")
hist(sapply(pwr_dat$clone, length), main = "", xlab = "Number of perturbed cells")
```

# Session info

```{r sessionInfo}
sessionInfo()
```

# References

<div id="refs"></div>